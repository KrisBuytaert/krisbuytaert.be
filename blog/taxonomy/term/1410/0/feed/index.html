<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xml:base="http://127.0.0.1:8080/blog"  xmlns:dc="http://purl.org/dc/elements/1.1/">
<channel>
 <title>Everything is a Freaking DNS problem - ci</title>
 <link>http://127.0.0.1:8080/blog/taxonomy/term/1410/0</link>
 <description></description>
 <language>en</language>
<item>
 <title>The power of packaging software, package all the things</title>
 <link>http://127.0.0.1:8080/blog/power-packaging-software-package-all-things</link>
 <description>&lt;p&gt;Software delivery is hard, plenty of people all over this planet are struggling with delivering software in their own controlled environment. They have invented great patterns that will build an artifact, then do some magic and the application is up and running.&lt;/p&gt;
&lt;p&gt;When talking about continuous delivery, people invariably discus their delivery pipeline and the different components that need to be in that pipeline.&lt;br /&gt;
Often, the focus on getting the application deployed or upgraded from that pipeline is so strong that teams&lt;br /&gt;
forget how to deploy their environment from scratch.&lt;/p&gt;
&lt;p&gt;After running a number of tests on the code , compiling it where needed, people want to move forward quickly and deploy their release artifact on an actual platform.&lt;br /&gt;
This deployment is typically via a file upload or a checkout from a source-control tool from the dedicated computer on which the application resides.&lt;br /&gt;
Sometimes, dedicated tools are integrated to simulate what a developer would do manually on a computer to get the application running.  Copy three files left, one right, and make sure you restart the service. Although this is obviously already a large improvement  over people manually pasting commands from a 42 page run book, it doesn’t solve all problems.&lt;/p&gt;
&lt;p&gt;Like the guy who quickly makes a change on the production server, never to commit the change, (say goodbye to git pull for your upgrade process)&lt;br /&gt;
If you package your software there are a couple of things you get for free from your packaging system.&lt;br /&gt;
Questions like, has this file been modified since I deployed it,  where did this file come from, when was it deployed,&lt;br /&gt;
what version of software  X do I have running on all my servers, are easily answered by the same&lt;br /&gt;
tools we use already for every other package on the system.   Not only can you use existing tools you are also using tools that are well known by your ops team and that they&lt;br /&gt;
already use for every other piece of software on your system.&lt;/p&gt;
&lt;p&gt;If your build process creates a package and uploads it to a package repository which is available for the hosts in the environment you want to deploy to, there is no need anymore for&lt;br /&gt;
a script that copies the artifact from a 3rd party location , and even less for that 42 page text document which never gets updated and still tells you to download yaja.3.1.9.war  from a location where you can only find&lt;br /&gt;
3.2 and 3.1.8 and the developer that knows if you can use 3.2 or why 3.1.9 got removed just left for the long weekend.&lt;/p&gt;
&lt;p&gt;Another, and maybe even more important thing, is the current sadly growing practice of having yet another tool in place that translates that 42 page text document to a bunch of shell scripts created from a drag and drop interface,  typically that &quot;deploy tool&quot; is even triggered from within the pipeline.   Apart from the fact that it usually stimulates a pattern of non reusable code, distributing even more ssh  keys , or adding yet another agent on all systems. it doesn’t take into account that you want to think of your servers as cattle and be able to deploy new instances of your application fast.&lt;br /&gt;
Do you really want to deploy your five new nodes on AWS  with a full Apache stack ready for production, then reconfigure your load balancers only to figure out that someone needs to go click in your continuous integration tool or deployment  to deploy the application to the new hosts? That one manual action someone forgets?&lt;br /&gt;
Imvho Deployment tools are a phase in the maturity process of a product team.. yes it&#039;s a step up from manually deploying software but it creates more and other problems , once your team grows in maturity refactoring out that tool is trivial.&lt;/p&gt;
&lt;p&gt;The obvious and trivial approach to this problem, and it comes with even more benefits. is called packaging. When you package your artifacts as operating system (e.g., .deb or .rpm) packages,&lt;br /&gt;
you can include that package in the list of packages to be deployed at installation time (via Kickstart or debootstrap). Similarly, when your configuration management tool&lt;br /&gt;
(e.g., Puppet or Chef) provisions the computer, you can specify which version of the application you want to have deployed by default.&lt;/p&gt;
&lt;p&gt;So, when you’re designing how you want to deploy your application, think about deploying new instances or deploying to existing setups (or rather, upgrading your application).&lt;br /&gt;
Doing so will make life so much easier when you want to deploy a new batch of servers.&lt;/p&gt;
</description>
 <comments>http://127.0.0.1:8080/blog/power-packaging-software-package-all-things#comments</comments>
 <category domain="http://127.0.0.1:8080/blog/category/cd">cd</category>
 <category domain="http://127.0.0.1:8080/blog/category/ci">ci</category>
 <category domain="http://127.0.0.1:8080/blog/category/deb">deb</category>
 <category domain="http://127.0.0.1:8080/blog/category/devops">devops</category>
 <category domain="http://127.0.0.1:8080/blog/category/opslife">opslife</category>
 <category domain="http://127.0.0.1:8080/blog/taxonomy/term/472">rpm</category>
 <pubDate>Tue, 28 Jul 2015 06:35:13 +0000</pubDate>
 <dc:creator>Kris Buytaert</dc:creator>
 <guid isPermaLink="false">1104 at http://127.0.0.1:8080/blog</guid>
</item>
<item>
 <title>Inuits Day </title>
 <link>http://127.0.0.1:8080/blog/inuits-day</link>
 <description>&lt;p&gt;Couple of Fridays ago we had one of our @Inuits days again.  Rather than having some people give talks and presentations about what they have been doing for the  past couple of months this time we set out to  research, test, and build stuff.&lt;/p&gt;
&lt;p&gt;We split up in 3 different groups,  one focusing on CI and testing freshly build stuff with cucumber,   a second one setup and tested &lt;a href=&quot;http://www.codership.com/products/galera_replication&quot; rel=&quot;nofollow&quot;&gt;Galera&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;We setup a 3 node Galera cluster , not really as smooth as we&#039;d like to ..&lt;/p&gt;
&lt;p&gt;Our first bump was that the installation of the package on CentOS is hell, it needs manual interaction such as replacing  packages.  Deploying this from a repository is probably not going to be a straight forward option.&lt;/p&gt;
&lt;p&gt;Galera only takes care of replicating data, just as with MySQL MM replication there still is a need for an external tool to define where to access the database, and implement monitoring in such a way that you are connecting to an up to date database.&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://poke152.blogspot.com/&quot; rel=&quot;nofollow&quot;&gt;Karl&lt;/a&gt; started wondering about Galera&#039;s locking,  turns out the locks aren&#039;t cluster wide, locks within the same node work fine.. so if galera is solely used for HA with 1 active node and X failover nodes, it will work (so all transactions happening on 1 node).&lt;/p&gt;
&lt;p&gt;We also ran into some issues when trying to start a node which couldn&#039;t contact the wsrep_cluster_address point (which is a node it will sync from at startup if specified in the wsrep.cnf file) , it just didn&#039;t want to start. This means that when the referenced node (configured in wsrep_cluster_address)is down, you will need to comment it out before you are able to start the mysql server.&lt;/p&gt;
&lt;p&gt;The fact that Galera replicates everythying brought us to the discussion if we really wanted that , or if we wanted more finegrained control over which databases or even tables we want to replicate and which ones we didn&#039;t want to replicate.  A minority of people wanted to replicate everything,  the majority of our group wanted finere grained control over what is being replicated to another node.&lt;/p&gt;
&lt;p&gt;I`m sure &lt;a href=&quot;http://www.lefred.be/&quot; rel=&quot;nofollow&quot;&gt;Lefred&lt;/a&gt; will shortly be writing about the progress his group made on &lt;a href=&quot;http://www.banquise.be/&quot; rel=&quot;nofollow&quot;&gt;Banquise&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The day ended as it should .. with BBQ and plenty of drinks&lt;/p&gt;
</description>
 <comments>http://127.0.0.1:8080/blog/inuits-day#comments</comments>
 <category domain="http://127.0.0.1:8080/blog/category/banquise">banquise</category>
 <category domain="http://127.0.0.1:8080/blog/category/ci">ci</category>
 <category domain="http://127.0.0.1:8080/blog/category/galera">galera</category>
 <category domain="http://127.0.0.1:8080/blog/taxonomy/term/520">inuits</category>
 <category domain="http://127.0.0.1:8080/blog/category/inuits-day">inuits day</category>
 <category domain="http://127.0.0.1:8080/blog/taxonomy/term/458">mysql</category>
 <pubDate>Mon, 21 Jun 2010 19:14:12 +0000</pubDate>
 <dc:creator>Kris Buytaert</dc:creator>
 <guid isPermaLink="false">1012 at http://127.0.0.1:8080/blog</guid>
</item>
</channel>
</rss>
